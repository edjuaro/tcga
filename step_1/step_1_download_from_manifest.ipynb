{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from subprocess import call\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import gzip\n",
    "import json\n",
    "# import sys\n",
    "\n",
    "\n",
    "def uncompress_gzip(file_name, new_name=None, delete=True):\n",
    "    # Read the stream and write that stream to a new file:\n",
    "    in_file = gzip.open(file_name, 'rb')\n",
    "    if new_name is None:\n",
    "        out_file = open(file_name.strip('.gz'), 'wb')\n",
    "    else:\n",
    "        out_file = open(new_name, 'wb')\n",
    "    out_file.write(in_file.read())\n",
    "    in_file.close()\n",
    "    out_file.close()\n",
    "    if delete:\n",
    "        os.remove(file_name)\n",
    "        \n",
    "def execute(comando, doitlive=False, input_to_use=None):\n",
    "    # result = subprocess.run(['ls', '-l'], stdout=subprocess.PIPE)\n",
    "    comando = comando.split(' ')\n",
    "\n",
    "    if doitlive:\n",
    "        popen = subprocess.Popen(comando, stdout=subprocess.PIPE, universal_newlines=True)\n",
    "        to_return = popen.stdout.read()\n",
    "        for line in to_return:\n",
    "            print(line, end='')\n",
    "        popen.stdout.close()\n",
    "        return_code = popen.wait()\n",
    "        if return_code:\n",
    "            raise subprocess.CalledProcessError(return_code, comando)\n",
    "    else:\n",
    "        if input_to_use is not None:\n",
    "            input_to_use = input_to_use.ecode('utf-8')\n",
    "        result = subprocess.run(comando, stdout=subprocess.PIPE, stderr=subprocess.PIPE, input=input_to_use)\n",
    "        to_return = result.stdout.decode('utf-8')\n",
    "        print(to_return)\n",
    "    return to_return.strip('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'BRCA_5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This download may take a while, please be patient.\n",
      "100% [#############################################] Time: 0:00:00   1.02  B/s \n",
      "\u001b[32mSuccessfully downloaded\u001b[0m: 4\n",
      "\n",
      "All files in manifest were downloaded, probably. To be sure, check the output of the gdc-client.\n"
     ]
    }
   ],
   "source": [
    "# Download from manifest\n",
    "manifest = \"gdc_manifest_20171221_005438.txt\"\n",
    "command = \"./gdc-client download -m \"+manifest\n",
    "print('This download may take a while, please be patient.')\n",
    "execute(command)\n",
    "print('All files in manifest were downloaded, probably. To be sure, check the output of the gdc-client.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read manifest and create a dictionary of useful data\n",
    "dfest = pd.read_table(manifest)\n",
    "\n",
    "# Parse metadata\n",
    "metadata_file = \"metadata.cart.2017-12-21T21_41_22.870798.json\"\n",
    "meta_data = json.load(open(metadata_file))\n",
    "\n",
    "# Make a dictionary to map file names to TCGA unique ID's\n",
    "#   # if we wanted to have only one sample per patient per \"phenotype\" we could use this:\n",
    "#   # meta_data[0]['cases'][0]['samples'][0]['submitter_id']\n",
    "#   # But since we want a unique ID for each HTSeq file (some patient/phenotypes will have multiple vials/replicates):\n",
    "#   # meta_data[0]['cases'][0]['samples'][0]['portions'][0]['analytes'][0]['aliquots'][0]['submitter_id']\n",
    "#   # Read more hre: https://wiki.nci.nih.gov/display/TCGA/Understanding+TCGA+Biospecimen+IDs\n",
    "name_id_dict = {}\n",
    "for i in range(len(meta_data)):\n",
    "    file_name = meta_data[i]['file_name']\n",
    "    unique_id = meta_data[i]['cases'][0]['samples'][0]['portions'][0]['analytes'][0]['aliquots'][0]['submitter_id']\n",
    "    name_id_dict[file_name] = unique_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/edjuaro/GoogleDrive/tcga/step_1\n",
      "\n",
      "All files were moved and \"decompressed\" successfully.\n"
     ]
    }
   ],
   "source": [
    "# pwd = os.path.dirname(__file__)\n",
    "pwd = execute('pwd')\n",
    "destination = os.path.join(pwd, 'raw_files')\n",
    "if not os.path.isdir(destination):\n",
    "    os.mkdir(destination)\n",
    "\n",
    "for d, f in zip(dfest['id'], dfest['filename']):\n",
    "    shutil.copy(os.path.join(d, f), destination)  # Move the downloaded files to a folder\n",
    "    shutil.rmtree(d)  # Remove those files/folders from current directory\n",
    "    # \"decompress\" and remove gz files\n",
    "    uncompress_gzip(os.path.join(destination, f), new_name=os.path.join(destination, name_id_dict[f]+'.htseq.counts'))\n",
    "print('All files were moved and \"decompressed\" successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From a list of HTSeq.counts files to a gct:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sample info file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict ={\n",
    "    '01':'Tumor',\n",
    "    '02':'Tumor',\n",
    "    '03':'Tumor',\n",
    "    '04':'Tumor',\n",
    "    '05':'Tumor',\n",
    "    '06':'Tumor',\n",
    "    '07':'Tumor',\n",
    "    '08':'Tumor',\n",
    "    '09':'Tumor',\n",
    "    '10':'Normal',\n",
    "    '11':'Normal',\n",
    "    '12':'Normal',\n",
    "    '13':'Normal',\n",
    "    '14':'Normal',\n",
    "    '15':'Normal',\n",
    "    '16':'Normal',\n",
    "    '17':'Normal',\n",
    "    '18':'Normal',\n",
    "    '19':'Normal',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'TCGA_'+dataset_name+'.txt'\n",
    "file = open(name, 'w')\n",
    "file.write('File\\tClass\\tSample_Name\\n')\n",
    "for f in dfest['filename']:\n",
    "    file.write('\\t'.join([name_id_dict[f]+'.htseq.counts',class_dict[name_id_dict[f][17:19]] ,name_id_dict[f]]))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDWIN: from here, call MergeHTSeqCounts... it may be tedious when there are thousands of files, but we gotta drink our own champaigne!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gp\n",
    "# # Create a GenePattern server proxy instance\n",
    "# gpserver = gp.GPServer('http://gp-beta-ami.genepattern.org/gp','edwin', 'nada')\n",
    "# module = gp.GPTask(gpserver, \"MergeHTSeqCounts\")  # Obtaining GPTask by module name\n",
    "# module.param_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_list = module.get_parameters()  # Get the list of GPParam objects\n",
    "\n",
    "# for param in params_list:  # Loop through each parameter\n",
    "#     print( param.get_name() )  # Print the parameter's name\n",
    "#     print( param.get_default_value() )  # Print the parameter's default value\n",
    "#     print( param.is_optional() )  # Print whether the parameter is optional\n",
    "#     print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
